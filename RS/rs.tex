%\documentstyle[11pt,a4]{article}
%\documentclass[a4paper]{article}
\documentclass[a4paper, 10pt]{article}
% Seems like it does not support 9pt and less. Anyways I should stick to 10pt.
%\documentclass[a4paper, 9pt]{article}
\topmargin-2.0cm

\usepackage{fancyhdr}
\usepackage{pagecounting}
\usepackage[dvips]{color}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{hyperref}

% Color Information from - http://www-h.eng.cam.ac.uk/help/tpl/textprocessing/latex_advanced/node13.html

% NEW COMMAND
% marginsize{left}{right}{top}{bottom}:
%\marginsize{3cm}{2cm}{1cm}{1cm}
%\marginsize{0.85in}{0.85in}{0.625in}{0.625in}

\def\ie{{\em i.e.,}}
\def\eg{{\em e.g.,}}
\newcommand{\tabref}[1]{Table~\ref{#1}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\comment}[1]{}

\advance\oddsidemargin-0.65in
%\advance\evensidemargin-1.5cm
\textheight9.2in
\textwidth6.75in
\newcommand\bb[1]{\mbox{\em #1}}
\def\baselinestretch{1.05}
%\pagestyle{empty}

\newcommand{\hsp}{\hspace*{\parindent}}
\definecolor{gray}{rgb}{0.4,0.4,0.4}
%\definecolor{gray}{rgb}{1.0,1.0,1.0}


\begin{document}
\thispagestyle{fancy}
%\pagenumbering{gobble}
%\fancyhead[location]{text} 
% Leave Left and Right Header empty.
\lhead{}
\rhead{}
%\rhead{\thepage}
\renewcommand{\headrulewidth}{0pt} 
\renewcommand{\footrulewidth}{0pt} 
\fancyfoot[C]{\footnotesize \textcolor{gray}{\href{https://norouzi.github.io/}{https://norouzi.github.io/}}} 

%\pagestyle{myheadings}
%\markboth{Sundar Iyer}{Sundar Iyer}

\pagestyle{fancy}
\lhead{\textcolor{gray}{\it Mohammad Norouzi}}
\rhead{\textcolor{gray}{\thepage/\totalpages{}}}
%\rhead{\thepage}
%\renewcommand{\headrulewidth}{0pt} 
%\renewcommand{\footrulewidth}{0pt} 
%\fancyfoot[C]{\footnotesize http://www.stanford.edu/$\sim$sundaes/application} 
%\ref{TotPages}

% This kind of makes 10pt to 9 pt.
%\begin{small}

%\vspace*{0.1cm}
\begin{center}
{\LARGE \bf Research Statement}\\
\vspace*{0.1cm}
{\normalsize Mohammad Norouzi (mnorouzi@google.com)}
\vspace*{0.2cm}
\end{center}
%\vspace*{0.2cm}

My research lies in {\em Machine Learning (ML)} with applications to
{\em Computer Vision} and {\em Natural Language Processing (NLP)}. I
study the mathematical principles and statistical modeling assumptions
that can lead to the emergence of {\em Artificial Intelligence (AI)}.
My research aims to develop simple and universal ML algorithms that
are broadly applicable across a range of problem domains including
computer vision and NLP. I am interested in bridging the gap between
existing ML formulations (\eg~see~\cite{raml,pcl,tpcl}) to help
simplify and unify common ML objective functions and deepen our
understanding of machine learning. My research makes heavy use of {\em
  deep neural networks} because of their flexibility and effectiveness
(\eg~\cite{wu2016gnmt,keypointnet,ocd}) and attempts to make neural
networks even more powerful and widely applicable.

%% I believe there exists simple and universal algorithms that can
%% successfully address many challenging ML problems. 
%% \begin{wrapfigure}{r}{2in}
%% %\begin{figure}
%% \vspace*{-.2cm}
%%   \includegraphics[width=2in]{fig1.png}
%% \vspace*{-.2cm}
%%   \caption{\small Figure from \cite{lecun98}, which highlights the
%%     inefficiency of traditional pattern recognition with separately
%%     tuned feature extraction and classification modules.}
%%   \label{fig:fig1}
%% \end{wrapfigure}
%(\eg~\figref{fig:fig1}).

My current research aims to enable effective and efficient {\em
  end-to-end} optimization of multi-stage ML pipelines such as
coversational agents and open-domain question answering systems, which
often involve {\em discrete} latent variables and {\em
  non-differentiable} components. I am inspired by the success of
error back back-propagation through multilayer neural networks to
jointly optimize hierarchical feature extraction and classification
modules~\cite{backprop,lecun98}.  My research aspires to facilitate
similar goal driven joint optimization of complex AI systems, which
comprise speech recogntion and synthesis, visual reasoning, natural
language processing, memory lookup, and logical reasoning modules. I
believe by adopting an end-to-end optimization approach, one can
achieve a higher degree of efficiency and effectiveness compared to
hand engineered ML pipelines, which involve separately optimized
modules.

My previous work has contributed to the core techniques needed for
{\em end-to-end} optimization of multi-stage ML pipelines and has
demonstrated the effectiveness of (1) end-to-end optimization of
metric learning and quantization modules~\cite{mlh,hdml}, (2)
non-greedy optimization of decision trees~\cite{engodt}, (3) joint
optimization of keypoint extraction and pose estimation
modules~\cite{keypointnet}, and (4) goal-driven optimization of
sequence models based on a sequence level reward
feedback~\cite{mapo,ocd}. Generally, end-to-end optimization based on
a well defined objective function offers a principled way to fine-tune
multi-stage pipelines and encourages error tolerance and effective
cooperation among different modules.
\comment{

 My research program aims to
facilitate end-to-end optimization of coversational agents and
open-domain question answering systems, which involve speech
recognition, information retrieval, interaction with humans and
database management systems, and speech synthesis.


For example, consider speech to speech translation which
can be done by stacking speech recognition, machine translation, and
speech synthesis, all of which have been developed in the ML and NLP
community. That said 
}

\vspace*{-.2cm}
\subsubsection*{End-to-end Stochastic Optimization of Discrete Latent Variables}
\vspace*{-.1cm}

\hspace{\parindent} {\em Discrete} latent variables are ubiquitous in
machine learning models, which utilize mixture of experts, efficient
lookup tables~\cite{mih}, hard attention~\cite{hardattention}, and
structured outputs. Using discrete variables as intermediate ML
representations often facilitates {\em efficiency} and {\em
  interpretability}. For example, consider a question answering system
that needs to convert natural language questions to output
answers. One can optimize a neural network to directly perform this
mapping, which requires the neural network to store the full knowledge
of the domain. Alternatively, one can train a neural network to first
convert a natural question to an intermediate SQL program, and then
execute the SQL program on a database of facts and relations to obtain
the final answer~\cite{mapo}. Having access to the underlying latent
programs allows one to update the facts without having to change the
neural network and gain insights into the inner workings of the
question answering system. For example, this would allow one to
attribute an incorrect answer to either an issue in the database or in
the model's understanding of the question. Interpretability is
especially important for sensitive application areas such as medicine
and public policy. Nevertheless, end-to-end optimization of discrete
variables is challenging due to lack of {\em differentiability}.

To differentiate through discrete latent variables, I advocate the use
of a stochastic relaxation of the objective functions in terms of an
expectation {\em w.\,r.\,t.}~a distribution over discrete
variables. For example, to optimize over latent programs, one can
maximize an expectation of a score function per program, where the
expectation is {\em w.\,r.\,t.}~a parametric distribution over all
possible programs.  Then, one can adopt ideas from {\em Reinforcement
Learning (RL)} and policy optimization~\cite{sutton1998reinforcement}
to optimize the stochastic objective function. We have applied the
REINFORCE algorithm~\cite{reinforce} and its variants to structured
output prediction~\cite{wu2016gnmt} and combinatorial optimization
with discrete structures~\cite{bello2016neural,azalia2017}. While this
approach to end-to-end optimization of discrete variables is
promising, a key limitation stems from the high variance of gradient
estimates because of Monte Carlo sampling.

A key theme in my research has been trying to bridge the gap between
policy optimization and supervised learning to avoid using high
variance gradient estimates (see~\cite{raml,pqt2018,ocd,dvn,mapo}).
In our recent work, we present Memory Augmented Policy Optimization
(MAPO)~\cite{mapo} as a way to incorporate off-policy trajectories to
reduce the variance of policy gradient estimates without introducing
any bias. MAPO achieves the state-of-the-art results in weakly
supervised semantic parsing. The independent work of Lieu {\em et
  al.}~\cite{liu2018rao} extends the application of MAPO to generative
models with discrete latent variables. Current formulation of MAPO is
limited to deterministic score functions, which makes this algorithm
not suitable for stochastic RL problems. I have developed a
generalization of MAPO based on control variates that makes this
approach more widely applicable, and we are currently performing
experiments on stochastic contextual bandit problems. I am also
planning to incorporate bootstrapping into the formulation of MAPO to
optimize long action trajectories. More generally, I am interested in
bridging the gap between imitation learning and RL algorithms,
extending our previous results~\cite{ocd} to facilitate more effective
optimization of discrete variables within ML.

\vspace*{-.2cm}
\subsubsection*{End-to-end Abstraction of Reinforcement Learning Problems}
\vspace*{-.1cm}

\hspace{\parindent} Pixel observations from RL environments are hardly
interpretable, even though the underlying dynamics are often
simple. One can think of the problem of recovering the underlying MDP
abstraction of an RL problem as another instance of learning discrete
latent representations. For example, consider an Atari game, in which
observations comprise $84\!\times\!84$ color images, while the
underlying dynamics can be defined in terms of relatively simple
rules. In many cases, one does not require access to the full image
observation for planning, but rather the core components of the game
such as locations of the agent, enemies, and obstacles are enough
to define an optimal policy. A key research question is how to
effectively learn an abstract representation of an RL problem to
facilitate efficient planning and exploration. In a recent
paper~\cite{coex}, we have shown that if one automatically discovers
higher level representations based on the position of the controllable
agent, then one can significantly improve performance by more
structured exploration.

From an end-to-end optimization perspective, the best way to evaluate
an abstraction of an RL problem is via examination of such an
abstraction in planning and policy optimization. Given observations
from an RL environment, I intend to automatically extract an MDP
abstraction and use it for planning such that one can differentiate
through the process of MDP abstraction and planning jointly. I would
like to make sure that optimal trajectories in the abstract MDP can be
translated back into near-optimal trajectories in the original
environment. Because the abstract MDP is fully observed, one can find
the optimal policy by efficient value or policy iteration, whereas the
original environment does not comply with such algorithms. An MDP
abstraction comprises a pre-specified number of abstract states, a
transition model between abstract states, and an abstract reward
function. For simplicity, we will assume that the abstract MDP and the
RL environment share the same set of possible actions. Furthermore, we
need a stochastic mapping from observations of the RL environment to
states of the abstract MDP. An important benefit of this approach is
that given the structure of the abstract MDP, one can {\em interpret} a
policy by visualizing the abstract state transitions and by clustering
the observations that represent the same abstract state.

\vspace*{-.2cm}
\subsubsection*{End-to-end Geometric Reasoning}
\vspace*{-.1cm}

\hspace{\parindent} Another example of interesting discrete structure
in machine learning is the 3D geometric structure shared by instances
of an object category. In a recent paper~\cite{keypointnet} for
end-to-end optimization of category-specific 3D keypoints, along with
their detectors, for a downstream geometric vision task. Given a
single image, we extract 3D keypoints that are consistent across
viewing angles and instances of the corresponding object category. We
make use of real valued keypoint coordinates for ease of optimization,
but, the difficulty lies in differentiating Through the geometric
reasoning module. We propose a differentiable objective function that
seeks the optimal list of keypoints for recovering the relative pose
between two views of an object, and we rely on differentiating through
Singular Value Decomposition (SVD) for optimization.  Importantly, we
find that our end-to-end geometric reasoning framework using no
ground-truth keypoint annotations outperforms a fully supervised
baseline (using the same neural network architecture) on the task of
pose estimation. I believe we need to come up with better ways of
incorporating 3D geometry into our generative and discriminative
neural networks, and KeypointNet is one step in that direction. I will
continue working on this problem, and inspired by some recent
work~\cite{kanazawa}, I have some concrete ideas to facilitate other
forms of end-to-end geometric reasoning for 3D pose and shape
reconstruction from a single image.

\vspace*{-.2cm}
\subsubsection*{Research on End-to-end Optimization of Discrete Structures}
\vspace*{-.1cm}

\hspace{\parindent} I believe that by end-to-end optimization of
multi-stage AI systems, one can achieve a higher degree of efficiency
and effectiveness. End-to-end optimization of discrete structures is
particularly important given the interpretability and efficiency
implications. I presented a few research directions in adopting
stochastic optimization for learning discrete internal representations
for structured prediction, program synthesis, and reinforcement
learning. I identified 3D vision tasks as another domain in which
end-to-end optimization is possible and fruitful.

\comment{
\vspace*{-.2cm}
\subsubsection*{Commercial and Public Engagement}
\vspace*{-.1cm}


\hspace{\parindent} My research focuses on developing Machine Learning
techniques for real world applications in Computer Vision and Natural
Language Processing. In my current position at Google Brain, I have
contributed to different AI and Machine Learning projects with a
significant commercial impact. I played a key role in the
development and launch of Google's neural machine translation
system~\cite{wu2016gnmt}. As a result of this contribution, the
quality of Google Translate has improved considerably and there has
been many positive feedback from the general public in using the
improved service for various language understanding applications. In a
separate project~\cite{liu2017,liu2018}, we have developed the
state-of-the-art image recognition system for cancer metastasis
detection in pathology images. I am happy to share that we are in the
process of training and testing this system on larger pathology
datasets and launching an automated pathology assistant to improve the
accuracy of cancer diagnosis. Further, our recent research on
automated program synthesis~\cite{pqt2018,mapo} has many potential
applications in question answering and software engineering
applications, and we are working with the corresponding product teams
at Google to apply our algorithms to improve Google's products.

In summary, I am excited about the future of Machine Learning, and I
am committed to continue my work on real world applications of Machine
Learning in language understanding, medical imaging, and automated
program synthesis. I believe my three years of work experience at
Google puts me in a strong position to lead research projects with a
significant commercial and societal impact.

%% Finally, I am also excited about the use
%% of machine learning for scientific discovery. I believe my research on
%% reinforcement learning and black box optimization
%}

\vspace{0.5cm}
}

%\begin{flushright}
%Mohammad Norouzi
%\end{flushright}

%\end{small}
%\newpage

%\begin{thebibliography}{deSolaPITH}
% Change font size?
% \tiny, \footnotesize, \small,\normalsize, \large, \Large, \LARGE, and \huge 
%\begin{small}
\begin{small}

\bibliographystyle{plain}
\bibliography{bib.bib}

\end{small}

\end{document}

